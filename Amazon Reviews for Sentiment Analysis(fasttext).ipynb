{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fastText is a library for efficient learning of word representations and sentence classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import fasttext\n",
    "import bz2\n",
    "import csv\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3600000\n"
     ]
    }
   ],
   "source": [
    "# Load the training data \n",
    "dt = bz2.BZ2File(\"train.ft.txt.bz2\")\n",
    "data = dt.readlines()\n",
    "train = [x.decode('utf-8') for x in data]\n",
    "print(len(train)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__label__2 Stuning even for the non-gamer: This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! ^_^\\n',\n",
       " \"__label__2 The best soundtrack ever to anything.: I'm reading a lot of reviews saying that this is the best 'game soundtrack' and I figured that I'd write a review to disagree a bit. This in my opinino is Yasunori Mitsuda's ultimate masterpiece. The music is timeless and I'm been listening to it for years now and its beauty simply refuses to fade.The price tag on this is pretty staggering I must say, but if you are going to buy any cd for this much money, this is the only one that I feel would be worth every penny.\\n\"]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Prep\n",
    "train = pd.DataFrame(train)\n",
    "train.to_csv(\"train.txt\", index=False, sep=' ', header=False, quoting=csv.QUOTE_NONE, quotechar=\"\", escapechar=\" \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fasttext.train_supervised('train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__label__2', '__label__1']\n"
     ]
    }
   ],
   "source": [
    "#print(model.words)\n",
    "print(model.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000 number of records in the test set\n"
     ]
    }
   ],
   "source": [
    "# Load the test data \n",
    "test = bz2.BZ2File(\"test.ft.txt.bz2\")\n",
    "test = test.readlines()\n",
    "test = [x.decode('utf-8') for x in test]\n",
    "print(len(test), 'number of records in the test set') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To run the predict function, we need to remove the __label__1 and __label__2 from the testset.  \n",
    "new = [w.replace('__label__2 ', '') for w in test]\n",
    "new = [w.replace('__label__1 ', '') for w in new]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = [w.replace('\\n', '') for w in new]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the predict function \n",
    "pred = model.predict(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__label__2'] is the predicted label\n",
      "[0.9946661] is the probability score\n"
     ]
    }
   ],
   "source": [
    "# check the first record outputs\n",
    "print(pred[0][0], 'is the predicted label')\n",
    "print(pred[1][0], 'is the probability score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9161699999999999\n"
     ]
    }
   ],
   "source": [
    "# Lets recode the actual targets to 1's and 0's from both the test set and the actual predictions  \n",
    "labels = [0 if x.split(' ')[0] == '__label__1' else 1 for x in test]\n",
    "pred_labels = [0 if x == ['__label__1'] else 1 for x in pred[0]]\n",
    "\n",
    "# run the accuracy measure. \n",
    "print(roc_auc_score(labels, pred_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compress model files with quantization\n",
    "\n",
    "When you want to save a supervised model file, fastText can compress it in order to have a much smaller model file by sacrificing only a little bit performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Prep\n",
    "test = pd.DataFrame(test)\n",
    "test.to_csv(\"test.txt\", index=False, sep=' ', header=False, quoting=csv.QUOTE_NONE, quotechar=\"\", escapechar=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with the previously trained `model` object, call :\n",
    "model.quantize(input='train.txt', retrain=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\t400000\n",
      "P@1\t0.915\n",
      "R@1\t0.915\n"
     ]
    }
   ],
   "source": [
    "#To evaluate our model by computing the precision at 1 (P@1) and the recall on a test set, we use the test function:\n",
    "\n",
    "def print_results(N, p, r):\n",
    "    print(\"N\\t\" + str(N))\n",
    "    print(\"P@{}\\t{:.3f}\".format(1, p))\n",
    "    print(\"R@{}\\t{:.3f}\".format(1, r))\n",
    "\n",
    "print_results(*model.test('test.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the new model :\n",
    "model.save_model(\"model_filename.ftz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
